{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeJNtBzkb/y8ATrSGo8Ee3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafael877/Google_Colab/blob/Alura/OK_googleAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks44gkJ_Rvnw",
        "outputId": "2b71a369-fc60-4e85-e6c3-bc580fd9d72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Importações e configuração do modelo) ...\n",
        "\n",
        "# Agente de Intenção (Interpretador de Pedidos) - Aprimorado\n",
        "def agente_intencao(pergunta_usuario):\n",
        "    prompt = f\"\"\"\n",
        "    Você é um Agente de Intenção com a personalidade de uma IA inteligente e conversacional. Sua tarefa é analisar a entrada do usuário, identificar o tipo de requisição e as informações relevantes, e também gerar uma **primeira resposta curta** que reconheça a pergunta e se posicione como uma IA prestativa.\n",
        "\n",
        "    **RETORNE APENAS O SEGUINTE BLOCO JSON VÁLIDO, SEM NENHUM TEXTO ADICIONAL ANTES OU DEPOIS:**\n",
        "    ```json\n",
        "    {{\n",
        "      \"tipo\": \"...\",\n",
        "      \"topico\": \"...\",\n",
        "      \"resposta_inicial\": \"...\"\n",
        "    }}\n",
        "    ```\n",
        "\n",
        "    Preencha os campos JSON de acordo com a entrada do usuário:\n",
        "\n",
        "    - 'tipo': O tipo principal da requisição ('pesquisa', 'informacao', etc.).\n",
        "    - 'topico': (Se aplicável) O principal tópico.\n",
        "    - 'acao': (Se aplicável) A ação específica.\n",
        "    - 'resposta_inicial': Uma frase curta (máximo 20 palavras) reconhecendo a pergunta e se identificando como uma IA. Use um tom natural e amigável. Por exemplo: \"Entendi sua pergunta sobre [tópico].\" ou \"Como uma IA, posso te ajudar com isso.\"\n",
        "    - Outras chaves relevantes.\n",
        "\n",
        "    **Exemplo de Entrada:** \"{pergunta_usuario}\"\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text.strip()\n",
        "\n",
        "# Agente buscador (simulado)\n",
        "def agente_buscador(topico):\n",
        "    prompt = f\"\"\"\n",
        "    Faça uma pesquisa fictícia e traga informações atuais e relevantes sobre: {topico}.\n",
        "    Seja objetivo e apresente fatos importantes que alguém realmente buscaria no Google.\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text\n",
        "\n",
        "# Agente resposta: transforma em linguagem natural COM personalidade de IA\n",
        "def agente_resposta_natural(info, resposta_inicial):\n",
        "    prompt = f\"\"\"\n",
        "    Você é uma IA conversacional com uma personalidade amigável e prestativa. Use a seguinte resposta inicial como ponto de partida e explique o conteúdo da pesquisa de forma natural, como se estivesse conversando com um usuário. Incorpore sua identidade como uma IA na resposta.\n",
        "\n",
        "    Resposta Inicial: \"{resposta_inicial}\"\n",
        "\n",
        "    Conteúdo da Pesquisa:\n",
        "    ---\n",
        "    {info}\n",
        "    ---\n",
        "\n",
        "    Gere uma resposta que seja informativa, fácil de entender e que soe como uma conversa real. Você pode fazer perguntas de acompanhamento ou oferecer ajuda adicional.\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text\n",
        "\n",
        "# Orquestrador principal\n",
        "def assistente_ia(pergunta_usuario):\n",
        "    print(f\"\\n[PERGUNTA] {pergunta_usuario}\")\n",
        "\n",
        "    # Usando o Agente de Intenção (Aprimorado)\n",
        "    intencao_str = agente_intencao(pergunta_usuario)\n",
        "    print(\"\\n[INTENÇÃO INTERPRETADA (BRUTA)]\\n\", intencao_str)\n",
        "\n",
        "    try:\n",
        "        # Usando regex para encontrar o bloco JSON dentro da string\n",
        "        import re\n",
        "        json_match = re.search(r'\\{(.*?)\\}', intencao_str, re.DOTALL)\n",
        "        if json_match:\n",
        "            json_str = \"{\" + json_match.group(1) + \"}\"\n",
        "            intencao = json.loads(json_str)\n",
        "            print(\"\\n[INTENÇÃO INTERPRETADA (PARSED)]\\n\", intencao)\n",
        "\n",
        "            tipo_requisicao = intencao.get(\"tipo\")\n",
        "            resposta_inicial = intencao.get(\"resposta_inicial\", \"\")\n",
        "\n",
        "            if resposta_inicial:\n",
        "                print(\"\\n[RESPOSTA INICIAL]\\n\", resposta_inicial)\n",
        "\n",
        "            if tipo_requisicao == \"pesquisa\":\n",
        "                topico_pesquisa = intencao.get(\"topico\")\n",
        "                if topico_pesquisa:\n",
        "                    dados_pesquisa = agente_buscador(topico_pesquisa)\n",
        "                    print(\"\\n[BUSCA SIMULADA]\\n\", dados_pesquisa)\n",
        "                    resposta_final = agente_resposta_natural(dados_pesquisa, resposta_inicial)\n",
        "                    print(\"\\n[RESPOSTA FINAL]\\n\", resposta_final)\n",
        "                else:\n",
        "                    print(\"\\n[AVISO] Tópico de pesquisa não encontrado na intenção.\")\n",
        "            elif tipo_requisicao == \"informacao\":\n",
        "                topico_info = intencao.get(\"topico\")\n",
        "                if topico_info:\n",
        "                    resposta_direta = agente_resposta_natural(f\"Você perguntou sobre: {topico_info}. No momento, não tenho informações detalhadas para fornecer diretamente. Talvez uma pesquisa possa ajudar?\", resposta_inicial) # Adaptado com resposta inicial\n",
        "                    print(\"\\n[RESPOSTA DIRETA]\\n\", resposta_direta)\n",
        "                else:\n",
        "                    print(\"\\n[AVISO] Tópico de informação não encontrado na intenção.\")\n",
        "            elif tipo_requisicao == \"agendamento\":\n",
        "                print(\"\\n[INFO] Requisição de agendamento detectada. Funcionalidade a ser implementada.\")\n",
        "                if resposta_inicial:\n",
        "                    print(resposta_inicial) # Exibe a resposta inicial mesmo sem ação\n",
        "            elif tipo_requisicao == \"execucao\":\n",
        "                print(\"\\n[INFO] Requisição de execução detectada. Funcionalidade a ser implementada.\")\n",
        "                if resposta_inicial:\n",
        "                    print(resposta_inicial) # Exibe a resposta inicial mesmo sem ação\n",
        "            elif tipo_requisicao == \"desconhecido\":\n",
        "                mensagem_desconhecida = intencao.get(\"mensagem\")\n",
        "                print(f\"\\n[RESPOSTA] {mensagem_desconhecida}\")\n",
        "            else:\n",
        "                print(\"\\n[AVISO] Tipo de requisição desconhecido:\", tipo_requisicao)\n",
        "\n",
        "        else:\n",
        "            print(\"\\n[ERRO] Bloco JSON não encontrado na resposta do Agente de Intenção.\")\n",
        "            print(\"Resposta bruta:\", intencao_str)\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"\\n[ERRO] Falha ao decodificar o JSON (após extração): {e}\")\n",
        "        print(\"Resposta bruta:\", intencao_str)\n",
        "    except AttributeError as e:\n",
        "        print(f\"\\n[ERRO] Erro ao acessar atributos da intenção: {e}\\nIntenção: {intencao}\")\n",
        "\n",
        "# Teste\n",
        "pergunta = \"Quando será o próximo evento de IA da Alura?\"\n",
        "assistente_ia(pergunta)\n",
        "\n",
        "pergunta_informacao = \"Qual a capital da Argentina?\"\n",
        "assistente_ia(pergunta_informacao)\n",
        "\n",
        "pergunta_desconhecida = \"Coisas aleatórias.\"\n",
        "assistente_ia(pergunta_desconhecida)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1K2sb_HbSL8d",
        "outputId": "5c13abe4-2a1e-46f2-e4f8-7192ba19d531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[PERGUNTA] Quando será o próximo evento de IA da Alura?\n",
            "\n",
            "[INTENÇÃO INTERPRETADA (BRUTA)]\n",
            " ```json\n",
            "{\n",
            "  \"tipo\": \"informacao\",\n",
            "  \"topico\": \"eventos de IA da Alura\",\n",
            "  \"resposta_inicial\": \"Olá! Posso te ajudar a descobrir quando será o próximo evento de IA da Alura.\"\n",
            "}\n",
            "```\n",
            "\n",
            "[INTENÇÃO INTERPRETADA (PARSED)]\n",
            " {'tipo': 'informacao', 'topico': 'eventos de IA da Alura', 'resposta_inicial': 'Olá! Posso te ajudar a descobrir quando será o próximo evento de IA da Alura.'}\n",
            "\n",
            "[RESPOSTA INICIAL]\n",
            " Olá! Posso te ajudar a descobrir quando será o próximo evento de IA da Alura.\n",
            "\n",
            "[RESPOSTA DIRETA]\n",
            " Olá! Posso te ajudar a descobrir quando será o próximo evento de IA da Alura.  Vi sua pergunta e, como uma IA conversacional, estou sempre aprendendo e me atualizando...  mas ainda não tenho acesso a um calendário oficial de eventos da Alura.  Desculpe por isso!\n",
            "\n",
            "Acho que uma busca na internet poderia nos ajudar bastante.  Você já tentou procurar no site da Alura, na seção de eventos ou notícias?  Eles normalmente anunciam eventos por lá.  Também podemos tentar procurar em redes sociais como o LinkedIn ou Twitter, usando palavras-chave como \"Alura\", \"Inteligência Artificial\" e \"evento\".\n",
            "\n",
            "O que você acha? Queremos tentar uma dessas buscas juntos, ou você prefere que eu tente pesquisar por você e te apresente os links que encontrar?  Qualquer coisa, estou aqui para te ajudar! 😊\n",
            "\n",
            "\n",
            "[PERGUNTA] Qual a capital da Argentina?\n",
            "\n",
            "[INTENÇÃO INTERPRETADA (BRUTA)]\n",
            " ```json\n",
            "{\n",
            "  \"tipo\": \"informacao\",\n",
            "  \"topico\": \"Geografia\",\n",
            "  \"resposta_inicial\": \"Olá! Como IA, posso te ajudar a descobrir a capital da Argentina.\"\n",
            "}\n",
            "```\n",
            "\n",
            "[INTENÇÃO INTERPRETADA (PARSED)]\n",
            " {'tipo': 'informacao', 'topico': 'Geografia', 'resposta_inicial': 'Olá! Como IA, posso te ajudar a descobrir a capital da Argentina.'}\n",
            "\n",
            "[RESPOSTA INICIAL]\n",
            " Olá! Como IA, posso te ajudar a descobrir a capital da Argentina.\n",
            "\n",
            "[RESPOSTA DIRETA]\n",
            " Olá! Como IA, posso te ajudar a descobrir a capital da Argentina... ou pelo menos, posso te ajudar a *encontrar* a resposta!  😊\n",
            "\n",
            "Vi que você fez uma pergunta sobre geografia, e especificamente sobre a capital da Argentina, mas minha base de dados ainda está um pouco limitada nesse assunto no momento.  Eu ainda estou aprendendo!  É como se eu estivesse estudando para um teste de geografia gigante e ainda não dominei todas as capitais. 😅\n",
            "\n",
            "Então, no lugar de te dar uma resposta direta (ainda!), posso te sugerir alguns lugares onde você pode procurar essa informação?  Podemos dar uma olhada em um mapa, por exemplo? Ou podemos usar um mecanismo de busca na internet como o Google? Qual opção você prefere?  Acho que seria bem mais rápido e eficiente.  \n",
            "\n",
            "Depois que encontrarmos a resposta, posso até te contar algumas curiosidades sobre Buenos Aires, se você quiser!  Qualquer coisa, é só me falar.  Vamos lá? 😉\n",
            "\n",
            "\n",
            "[PERGUNTA] Coisas aleatórias.\n",
            "\n",
            "[INTENÇÃO INTERPRETADA (BRUTA)]\n",
            " ```json\n",
            "{\n",
            "  \"tipo\": \"pesquisa\",\n",
            "  \"topico\": \"coisas aleatórias\",\n",
            "  \"resposta_inicial\": \"Entendi sua busca por coisas aleatórias. Como IA, posso te ajudar!\"\n",
            "}\n",
            "```\n",
            "\n",
            "[INTENÇÃO INTERPRETADA (PARSED)]\n",
            " {'tipo': 'pesquisa', 'topico': 'coisas aleatórias', 'resposta_inicial': 'Entendi sua busca por coisas aleatórias. Como IA, posso te ajudar!'}\n",
            "\n",
            "[RESPOSTA INICIAL]\n",
            " Entendi sua busca por coisas aleatórias. Como IA, posso te ajudar!\n",
            "\n",
            "[BUSCA SIMULADA]\n",
            " ## Pesquisa Fictícia: Coisas Aleatórias - Dados de Outubro de 2023\n",
            "\n",
            "**1.  Aumento da Popularidade de Esportes Incomuns:**\n",
            "\n",
            "* **Fato:** Observa-se um crescimento significativo na procura por informações e participação em esportes considerados \"incomuns\", como *kin-ball*, *bossaball* e *sepak takraw*.  Plataformas de mídia social como o TikTok contribuem para essa tendência, exibindo vídeos virais de partidas e tutoriais.\n",
            "* **Importância:**  Reflete uma mudança de comportamento do consumidor, buscando experiências alternativas e  comunidades mais nichadas.  Potencial de crescimento econômico para marcas que investem em equipamentos e eventos relacionados.\n",
            "\n",
            "**2.  Impacto da IA na Composição Musical:**\n",
            "\n",
            "* **Fato:** Ferramentas de IA generativa estão revolucionando a composição musical, permitindo a criação de novas melodias e arranjos com base em parâmetros específicos.  A discussão ética sobre autoria e direitos autorais está em ascensão.\n",
            "* **Importância:**  Transformação profunda na indústria musical, com impacto em compositores, músicos e gravadoras.  Preocupações sobre a originalidade e a substituição de músicos humanos.\n",
            "\n",
            "**3.  Tendências de Nomes de Bebês:**\n",
            "\n",
            "* **Fato:**  Nomes de bebês com origens nórdicas e com significados ligados à natureza estão em alta.  Observa-se também uma crescente preferência por nomes curtos e fáceis de pronunciar, em contraste com nomes longos e incomuns das últimas décadas.\n",
            "* **Importância:**  Reflete mudanças culturais e sociais, influenciando a percepção de identidade e individualidade.  Tendência impactando a indústria de produtos para bebês e serviços de registro civil.\n",
            "\n",
            "**4.  O Mercado de Plantas Raras e Colecionáveis:**\n",
            "\n",
            "* **Fato:**  A procura por plantas raras e de colecionador aumentou significativamente, impulsionada pela crescente popularidade de plantas de interior e pelo desenvolvimento de comunidades online de entusiastas.  Isso levou à criação de um mercado online próspero e à especulação de preços.\n",
            "* **Importância:**  Indica um interesse crescente pela jardinagem e pela conexão com a natureza, impactando a indústria de plantas ornamentais e o mercado de e-commerce.  Também destaca questões de sustentabilidade e conservação de espécies.\n",
            "\n",
            "**5.  Desenvolvimento de Novas Tecnologias de Reciclagem:**\n",
            "\n",
            "* **Fato:**  Pesquisa e desenvolvimento de novas tecnologias de reciclagem de plásticos e outros materiais estão ganhando impulso, com foco em métodos mais eficientes e sustentáveis, incluindo o uso de inteligência artificial para otimizar o processo.\n",
            "* **Importância:**  Fundamental para a sustentabilidade ambiental, com potencial para reduzir a poluição e o impacto ambiental da produção de resíduos.  Influencia políticas governamentais e investimentos em tecnologias verdes.\n",
            "\n",
            "\n",
            "**Observação:** Esta pesquisa é fictícia e os dados apresentados são inventados para fins ilustrativos.  Apesar da natureza fictícia, as tendências descritas refletem áreas de interesse atuais e relevantes.\n",
            "\n",
            "\n",
            "[RESPOSTA FINAL]\n",
            " Oi! Entendi sua busca por coisas aleatórias. Como IA, posso te ajudar!  Olha só o que eu achei nessa pesquisa fictícia de outubro de 2023 –  é bem interessante!  Parece que várias coisas bem diferentes estão acontecendo por aí.\n",
            "\n",
            "Primeiro, tem um boom de esportes inusitados!  Kin-ball, bossaball, sepak takraw…  já ouviu falar?  Aparentemente, o TikTok tá dando uma força enorme pra isso, com vídeos virais mostrando as partidas.  Isso mostra como as pessoas estão buscando coisas diferentes e comunidades menores, né?  Até dá pra imaginar o potencial econômico disso tudo, com empresas investindo em equipamentos e eventos.\n",
            "\n",
            "Depois, a música está mudando com a IA!  Programas de computador estão compondo músicas, o que é bem fascinante, mas também levanta questões éticas sobre quem é o autor de verdade.  Imagina o impacto disso na indústria musical, tanto pra compositores quanto pra gravadoras!  Será que os músicos humanos vão ser substituídos? Essa é uma pergunta que fica no ar.\n",
            "\n",
            "No mundo dos bebês,  nomes de origem nórdica e ligados à natureza estão super na moda.  Nomes curtos e fáceis também estão ganhando espaço.  É curioso observar como isso reflete as mudanças na nossa sociedade, né?  Até a indústria de produtos para bebês e os cartórios de registro civil devem estar sentindo o impacto dessa tendência.\n",
            "\n",
            "Falando em tendências, as plantas raras estão bombando!  As pessoas estão criando verdadeiras coleções de plantas, principalmente de interior, e  isso gerou até um mercado online bem ativo, com preços às vezes bem altos.  Mostra como as pessoas estão buscando uma conexão maior com a natureza, certo?  Mas também precisamos pensar na sustentabilidade e na conservação dessas espécies.\n",
            "\n",
            "Por fim, tem muita coisa acontecendo na área de reciclagem!  Estão surgindo tecnologias novas e mais eficientes, inclusive com a ajuda da inteligência artificial.  Isso é super importante para o meio ambiente, né?  Afinal, reduzir a poluição é essencial.  Imagino que governos e empresas de tecnologia verde estão de olho nisso.\n",
            "\n",
            "E aí, o que achou? Tem alguma dessas tendências que te chamou mais a atenção?  Você gostaria que eu explorasse algum desses tópicos com mais detalhes?  Como IA, estou aqui para te ajudar a descobrir mais sobre o que te interessa!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Instalar o pacote correto\n",
        "!pip install -U google-generativeai\n",
        "\n",
        "from google.colab import userdata\n",
        "userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Importações\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# Substitua pela sua API Key do Gemini\n",
        "# Substitua \"SUA_CHAVE_AQUI\" pela sua chave de API real do Gemini\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_ACTUAL_API_KEY\"\n",
        "\n",
        "# Configura o modelo\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "modelo = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Agente interpretador: detecta se é pesquisa, tarefa ou dúvida\n",
        "def interpretar_intencao(pergunta):\n",
        "    prompt = f\"\"\"\n",
        "    Classifique a intenção da seguinte frase do usuário. Responda só em JSON válido, sem explicações:\n",
        "\n",
        "    Frase: \"{pergunta}\"\n",
        "\n",
        "    Formato: {{\n",
        "      \"tipo\": \"pesquisa\" | \"tarefa\" | \"dúvida\",\n",
        "      \"topico\": \"<resumo curto do assunto>\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text\n",
        "\n",
        "# Agente buscador (simulado): só resume a busca como exemplo\n",
        "def buscar_topico(topico):\n",
        "    prompt = f\"\"\"\n",
        "    Faça uma pesquisa fictícia e traga informações atuais e relevantes sobre: {topico}.\n",
        "    Seja objetivo e apresente fatos importantes que alguém realmente buscaria no Google.\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text\n",
        "\n",
        "# Agente resposta: transforma em linguagem natural\n",
        "def gerar_resposta_natural(info):\n",
        "    prompt = f\"\"\"\n",
        "    Explique para um amigo o seguinte conteúdo de forma natural e fácil de entender:\n",
        "    ---\n",
        "    {info}\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text\n",
        "\n",
        "# Orquestrador principal\n",
        "def assistente_ia(pergunta_usuario):\n",
        "    print(f\"\\n[PERGUNTA] {pergunta_usuario}\")\n",
        "\n",
        "    intencao = interpretar_intencao(pergunta_usuario)\n",
        "    print(\"\\n[INTENÇÃO INTERPRETADA]\\n\", intencao)\n",
        "\n",
        "    if '\"tipo\": \"pesquisa\"' in intencao:\n",
        "        # Handle potential JSON parsing errors more robustly\n",
        "        try:\n",
        "            import json\n",
        "            intencion_data = json.loads(intencao)\n",
        "            topico_inicio = intencion_data.get(\"topico\", \"\") # Use .get to avoid KeyError\n",
        "        except (json.JSONDecodeError, AttributeError) as e:\n",
        "            print(f\"\\n[ERROR] Failed to parse intention JSON: {e}\")\n",
        "            topico_inicio = \"\" # Set a default or handle the error as needed\n",
        "\n",
        "        if topico_inicio:\n",
        "            dados_pesquisa = buscar_topico(topico_inicio)\n",
        "            print(\"\\n[BUSCA SIMULADA]\\n\", dados_pesquisa)\n",
        "\n",
        "            resposta_final = gerar_resposta_natural(dados_pesquisa)\n",
        "            print(\"\\n[RESPOSTA FINAL]\\n\", resposta_final)\n",
        "        else:\n",
        "             print(\"\\n[INFO] Tópico não encontrado na intenção.\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\n[INFO] Não é uma pesquisa. Intenção interpretada:\", intencao)\n",
        "\n",
        "# Teste\n",
        "pergunta = \"Quando será o próximo evento de IA da Alura?\"\n",
        "assistente_ia(pergunta)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "id": "ZnxrOpUaSdpb",
        "outputId": "2e8b86d8-a29c-4669-840d-285e8aa553a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n",
            "\n",
            "[PERGUNTA] Quando será o próximo evento de IA da Alura?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1139.73ms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequest",
          "evalue": "400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: API key not valid. Please pass a valid API key.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d5a2062518ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m# Teste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mpergunta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Quando será o próximo evento de IA da Alura?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0massistente_ia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpergunta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-d5a2062518ac>\u001b[0m in \u001b[0;36massistente_ia\u001b[0;34m(pergunta_usuario)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n[PERGUNTA] {pergunta_usuario}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mintencao\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpretar_intencao\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpergunta_usuario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[INTENÇÃO INTERPRETADA]\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintencao\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d5a2062518ac>\u001b[0m in \u001b[0;36minterpretar_intencao\u001b[0;34m(pergunta)\u001b[0m\n\u001b[1;32m     29\u001b[0m     }}\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mresposta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresposta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequest\u001b[0m: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: API key not valid. Please pass a valid API key."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar o pacote correto\n",
        "!pip install -U google-generativeai\n",
        "\n",
        "# Importações\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Configurar o modelo usando chave salva no Colab\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "modelo = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Agente interpretador: detecta se é pesquisa, tarefa ou dúvida\n",
        "def interpretar_intencao(pergunta):\n",
        "    prompt = f\"\"\"\n",
        "    Classifique a intenção da seguinte frase do usuário. Responda só em JSON válido, sem explicações:\n",
        "\n",
        "    Frase: \"{pergunta}\"\n",
        "\n",
        "    Formato: {{\n",
        "      \"tipo\": \"pesquisa\" | \"tarefa\" | \"dúvida\",\n",
        "      \"topico\": \"<resumo curto do assunto>\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text\n",
        "\n",
        "# Agente buscador (simulado): só resume a busca como exemplo\n",
        "def buscar_topico(topico):\n",
        "    prompt = f\"\"\"\n",
        "    Faça uma pesquisa fictícia e traga informações atuais e relevantes sobre: {topico}.\n",
        "    Seja objetivo e apresente fatos importantes que alguém realmente buscaria no Google.\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text\n",
        "\n",
        "# Agente resposta: transforma em linguagem natural\n",
        "def gerar_resposta_natural(info):\n",
        "    prompt = f\"\"\"\n",
        "    Explique para um amigo o seguinte conteúdo de forma natural e fácil de entender:\n",
        "    ---\n",
        "    {info}\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text\n",
        "\n",
        "# Orquestrador principal\n",
        "def assistente_ia(pergunta_usuario):\n",
        "    print(f\"\\n[PERGUNTA] {pergunta_usuario}\")\n",
        "\n",
        "    intencao = interpretar_intencao(pergunta_usuario)\n",
        "    print(\"\\n[INTENÇÃO INTERPRETADA]\\n\", intencao)\n",
        "\n",
        "    if '\"tipo\": \"pesquisa\"' in intencao:\n",
        "        try:\n",
        "            intencao_data = json.loads(intencao)\n",
        "            topico_inicio = intencao_data.get(\"topico\", \"\")\n",
        "        except (json.JSONDecodeError, AttributeError) as e:\n",
        "            print(f\"\\n[ERRO] Falha ao ler o JSON da intenção: {e}\")\n",
        "            topico_inicio = \"\"\n",
        "\n",
        "        if topico_inicio:\n",
        "            dados_pesquisa = buscar_topico(topico_inicio)\n",
        "            print(\"\\n[BUSCA SIMULADA]\\n\", dados_pesquisa)\n",
        "\n",
        "            resposta_final = gerar_resposta_natural(dados_pesquisa)\n",
        "            print(\"\\n[RESPOSTA FINAL]\\n\", resposta_final)\n",
        "        else:\n",
        "            print(\"\\n[INFO] Tópico não identificado.\")\n",
        "    else:\n",
        "        print(\"\\n[INFO] Não é uma pesquisa. Intenção interpretada:\", intencao)\n",
        "\n",
        "# Teste\n",
        "pergunta = \"Quando será o próximo evento de IA da Alura?\"\n",
        "assistente_ia(pergunta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "FolVD7MPTapY",
        "outputId": "cb299118-73e1-409a-f54d-b715c89f1331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n",
            "\n",
            "[PERGUNTA] Quando será o próximo evento de IA da Alura?\n",
            "\n",
            "[INTENÇÃO INTERPRETADA]\n",
            " ```json\n",
            "{\n",
            "  \"tipo\": \"dúvida\",\n",
            "  \"topico\": \"Próximo evento de IA da Alura\"\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "[INFO] Não é uma pesquisa. Intenção interpretada: ```json\n",
            "{\n",
            "  \"tipo\": \"dúvida\",\n",
            "  \"topico\": \"Próximo evento de IA da Alura\"\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Importações e configuração do modelo) ...\n",
        "\n",
        "# Agente de Intenção (Interpretador de Pedidos) - Aprimorado\n",
        "def agente_intencao(pergunta_usuario):\n",
        "    prompt = f\"\"\"\n",
        "    Você é um Agente de Intenção com a personalidade de uma IA inteligente e conversacional. Sua tarefa é analisar a entrada do usuário, identificar o tipo de requisição e as informações relevantes, e também gerar uma **primeira resposta curta** que reconheça a pergunta e se posicione como uma IA prestativa.\n",
        "\n",
        "    **RETORNE APENAS O SEGUINTE BLOCO JSON VÁLIDO, SEM NENHUM TEXTO ADICIONAL ANTES OU DEPOIS:**\n",
        "    ```json\n",
        "    {{\n",
        "      \"tipo\": \"...\",\n",
        "      \"topico\": \"...\",\n",
        "      \"resposta_inicial\": \"...\"\n",
        "    }}\n",
        "    ```\n",
        "\n",
        "    Preencha os campos JSON de acordo com a entrada do usuário:\n",
        "\n",
        "    - 'tipo': O tipo principal da requisição ('pesquisa', 'informacao', etc.).\n",
        "    - 'topico': (Se aplicável) O principal tópico.\n",
        "    - 'acao': (Se aplicável) A ação específica.\n",
        "    - 'resposta_inicial': Uma frase curta (máximo 20 palavras) reconhecendo a pergunta e se identificando como uma IA. Use um tom natural e amigável. Por exemplo: \"Entendi sua pergunta sobre [tópico].\" ou \"Como uma IA, posso te ajudar com isso.\"\n",
        "    - Outras chaves relevantes.\n",
        "\n",
        "    **Exemplo de Entrada:** \"{pergunta_usuario}\"\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    # Acessar o atributo 'text' da resposta antes de usar strip()\n",
        "    return resposta.text.strip()\n",
        "\n",
        "# Agente buscador (simulado)\n",
        "def agente_buscador(topico):\n",
        "    prompt = f\"\"\"\n",
        "    Faça uma pesquisa fictícia e traga informações atuais e relevantes sobre: {topico}.\n",
        "    Seja objetivo e apresente fatos importantes que alguém realmente buscaria no Google.\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text\n",
        "\n",
        "# Agente resposta: transforma em linguagem natural COM personalidade de IA\n",
        "def agente_resposta_natural(info, resposta_inicial):\n",
        "    prompt = f\"\"\"\n",
        "    Você é uma IA conversacional com uma personalidade amigável e prestativa. Use a seguinte resposta inicial como ponto de partida e explique o conteúdo da pesquisa de forma natural, como se estivesse conversando com um usuário. Incorpore sua identidade como uma IA na resposta.\n",
        "\n",
        "    Resposta Inicial: \"{resposta_inicial}\"\n",
        "\n",
        "    Conteúdo da Pesquisa:\n",
        "    ---\n",
        "    {info}\n",
        "    ---\n",
        "\n",
        "    Gere uma resposta que seja informativa, fácil de entender e que soe como uma conversa real. Você pode fazer perguntas de acompanhamento ou oferecer ajuda adicional.\n",
        "    \"\"\"\n",
        "    resposta = modelo.generate_content(prompt)\n",
        "    return resposta.text\n",
        "\n",
        "# Orquestrador principal\n",
        "def assistente_ia(pergunta_usuario):\n",
        "    print(f\"\\n[PERGUNTA] {pergunta_usuario}\")\n",
        "\n",
        "    # Usando o Agente de Intenção (Aprimorado)\n",
        "    intencao_str = agente_intencao(pergunta_usuario)\n",
        "    print(\"\\n[INTENÇÃO INTERPRETADA]\\n\", intencao_str)\n",
        "\n",
        "    try:\n",
        "        intencao = json.loads(intencao_str)\n",
        "        tipo_requisicao = intencao.get(\"tipo\")\n",
        "        resposta_inicial = intencao.get(\"resposta_inicial\", \"\")\n",
        "\n",
        "        if resposta_inicial:\n",
        "            print(\"\\n[RESPOSTA INICIAL]\\n\", resposta_inicial)\n",
        "\n",
        "        if tipo_requisicao == \"pesquisa\":\n",
        "            topico_pesquisa = intencao.get(\"topico\")\n",
        "            if topico_pesquisa:\n",
        "                dados_pesquisa = agente_buscador(topico_pesquisa)\n",
        "                print(\"\\n[BUSCA SIMULADA]\\n\", dados_pesquisa)\n",
        "                resposta_final = agente_resposta_natural(dados_pesquisa, resposta_inicial)\n",
        "                print(\"\\n[RESPOSTA FINAL]\\n\", resposta_final)\n",
        "            else:\n",
        "                print(\"\\n[AVISO] Tópico de pesquisa não encontrado na intenção.\")\n",
        "        elif tipo_requisicao == \"informacao\":\n",
        "            topico_info = intencao.get(\"topico\")\n",
        "            if topico_info:\n",
        "                resposta_direta = agente_resposta_natural(f\"Você perguntou sobre: {topico_info}. No momento, não tenho informações detalhadas para fornecer diretamente. Talvez uma pesquisa possa ajudar?\", resposta_inicial) # Adaptado com resposta inicial\n",
        "                print(\"\\n[RESPOSTA DIRETA]\\n\", resposta_direta)\n",
        "            else:\n",
        "                print(\"\\n[AVISO] Tópico de informação não encontrado na intenção.\")\n",
        "        elif tipo_requisicao == \"agendamento\":\n",
        "            print(\"\\n[INFO] Requisição de agendamento detectada. Funcionalidade a ser implementada.\")\n",
        "            if resposta_inicial:\n",
        "                print(resposta_inicial) # Exibe a resposta inicial mesmo sem ação\n",
        "        elif tipo_requisicao == \"execucao\":\n",
        "            print(\"\\n[INFO] Requisição de execução detectada. Funcionalidade a ser implementada.\")\n",
        "            if resposta_inicial:\n",
        "                print(resposta_inicial) # Exibe a resposta inicial mesmo sem ação\n",
        "        elif tipo_requisicao == \"desconhecido\":\n",
        "            mensagem_desconhecida = intencao.get(\"mensagem\")\n",
        "            print(f\"\\n[RESPOSTA] {mensagem_desconhecida}\")\n",
        "        else:\n",
        "            print(\"\\n[AVISO] Tipo de requisição desconhecido:\", tipo_requisicao)\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"\\n[ERRO] Falha ao decodificar a resposta do Agente de Intenção: {e}\\nResposta bruta: {intencao_str}\")\n",
        "    except AttributeError as e:\n",
        "        print(f\"\\n[ERRO] Erro ao acessar atributos da intenção: {e}\\nIntenção: {intencao}\")\n",
        "\n",
        "# Teste\n",
        "pergunta = \"Quando será o próximo evento de IA da Alura?\"\n",
        "assistente_ia(pergunta)\n",
        "\n",
        "pergunta_informacao = \"Qual a capital da Argentina?\"\n",
        "assistente_ia(pergunta_informacao)\n",
        "\n",
        "pergunta_desconhecida = \"Coisas aleatórias.\"\n",
        "assistente_ia(pergunta_desconhecida)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "elMJxE83VHDv",
        "outputId": "42062672-5aeb-428c-a846-f3637b80ab75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[PERGUNTA] Quando será o próximo evento de IA da Alura?\n",
            "\n",
            "[INTENÇÃO INTERPRETADA]\n",
            " ```json\n",
            "{\n",
            "  \"tipo\": \"informacao\",\n",
            "  \"topico\": \"eventos de IA da Alura\",\n",
            "  \"resposta_inicial\": \"Olá! Como IA, posso te ajudar a descobrir quando será o próximo evento de IA da Alura.\"\n",
            "}\n",
            "```\n",
            "\n",
            "[ERRO] Falha ao decodificar a resposta do Agente de Intenção: Expecting value: line 1 column 1 (char 0)\n",
            "Resposta bruta: ```json\n",
            "{\n",
            "  \"tipo\": \"informacao\",\n",
            "  \"topico\": \"eventos de IA da Alura\",\n",
            "  \"resposta_inicial\": \"Olá! Como IA, posso te ajudar a descobrir quando será o próximo evento de IA da Alura.\"\n",
            "}\n",
            "```\n",
            "\n",
            "[PERGUNTA] Qual a capital da Argentina?\n",
            "\n",
            "[INTENÇÃO INTERPRETADA]\n",
            " ```json\n",
            "{\n",
            "  \"tipo\": \"informacao\",\n",
            "  \"topico\": \"Geografia\",\n",
            "  \"resposta_inicial\": \"Olá! Como IA, posso te ajudar a descobrir a capital da Argentina.\"\n",
            "}\n",
            "```\n",
            "\n",
            "[ERRO] Falha ao decodificar a resposta do Agente de Intenção: Expecting value: line 1 column 1 (char 0)\n",
            "Resposta bruta: ```json\n",
            "{\n",
            "  \"tipo\": \"informacao\",\n",
            "  \"topico\": \"Geografia\",\n",
            "  \"resposta_inicial\": \"Olá! Como IA, posso te ajudar a descobrir a capital da Argentina.\"\n",
            "}\n",
            "```\n",
            "\n",
            "[PERGUNTA] Coisas aleatórias.\n",
            "\n",
            "[INTENÇÃO INTERPRETADA]\n",
            " ```json\n",
            "{\n",
            "  \"tipo\": \"pesquisa\",\n",
            "  \"topico\": \"assuntos aleatórios\",\n",
            "  \"resposta_inicial\": \"Olá! Posso te ajudar a encontrar informações sobre coisas aleatórias.\"\n",
            "}\n",
            "```\n",
            "\n",
            "[ERRO] Falha ao decodificar a resposta do Agente de Intenção: Expecting value: line 1 column 1 (char 0)\n",
            "Resposta bruta: ```json\n",
            "{\n",
            "  \"tipo\": \"pesquisa\",\n",
            "  \"topico\": \"assuntos aleatórios\",\n",
            "  \"resposta_inicial\": \"Olá! Posso te ajudar a encontrar informações sobre coisas aleatórias.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    }
  ]
}